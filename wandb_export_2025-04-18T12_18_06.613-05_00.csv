"Name","ID","User","Group","Job Type","Sweep","Description","GPU Count","_attn_implementation_autoset","_name_or_path","accelerator_config.even_batches","accelerator_config.non_blocking","accelerator_config.split_batches","accelerator_config.use_seedable_sampler","adafactor","adam_beta1","adam_beta2","adam_epsilon","add_cross_attention","architectures","attention_dropout","auto_find_batch_size","average_tokens_across_devices","batch_eval_metrics","bf16","bf16_full_eval","bos_token_id","chunk_size_feed_forward","classifier_dropout","d_ff","d_kv","d_model","dataloader_drop_last","dataloader_num_workers","dataloader_persistent_workers","dataloader_pin_memory","ddp_timeout","debug","decoder_start_token_id","dense_act_fn","disable_tqdm","diversity_penalty","do_eval","do_predict","do_sample","do_train","dropout_rate","early_stopping","encoder_no_repeat_ngram_size","eos_token_id","eval_delay","eval_do_concat_batches","eval_on_start","eval_strategy","eval_use_gather_object","evaluation_strategy","feed_forward_proj","fp16","fp16_backend","fp16_full_eval","fp16_opt_level","fsdp","fsdp_config.min_num_params","fsdp_config.xla","fsdp_config.xla_fsdp_grad_ckpt","fsdp_config.xla_fsdp_v2","fsdp_min_num_params","full_determinism","gradient_accumulation_steps","gradient_checkpointing","greater_is_better","group_by_length","half_precision_backend","head_dim","hidden_act","hidden_size","hub_always_push","hub_strategy","hub_token","id2label.0","id2label.1","ignore_data_skip","include_for_metrics","include_inputs_for_metrics","include_num_input_tokens_seen","include_tokens_per_second","initializer_factor","initializer_range","intermediate_size","is_decoder","is_encoder_decoder","is_gated_act","jit_mode_eval","label2id.LABEL_0","label2id.LABEL_1","label_smoothing_factor","layer_norm_epsilon","learning_rate","length_column_name","length_penalty","load_best_model_at_end","local_rank","log_level","log_level_replica","log_on_each_node","logging_dir","logging_first_step","logging_nan_inf_filter","logging_steps","logging_strategy","lr_scheduler_type","max_grad_norm","max_length","max_position_embeddings","max_steps","metric_for_best_model","min_length","model/num_parameters","model_type","mp_parameters","n_positions","no_cuda","no_repeat_ngram_size","num_attention_heads","num_beam_groups","num_beams","num_decoder_layers","num_heads","num_hidden_layers","num_key_value_heads","num_layers","num_return_sequences","num_train_epochs","optim","output_attentions","output_dir","output_hidden_states","output_past","output_scores","overwrite_output_dir","pad_token_id","past_index","peft_config.default.base_model_name_or_path","peft_config.default.bias","peft_config.default.fan_in_fan_out","peft_config.default.inference_mode","peft_config.default.init_lora_weights","peft_config.default.lora_alpha","peft_config.default.lora_bias","peft_config.default.lora_dropout","peft_config.default.megatron_core","peft_config.default.peft_type","peft_config.default.r","peft_config.default.runtime_config.ephemeral_gpu_offload","peft_config.default.target_modules","peft_config.default.task_type","peft_config.default.use_dora","peft_config.default.use_rslora","per_device_eval_batch_size","per_device_train_batch_size","prediction_loss_only","push_to_hub","push_to_hub_token","quantization_config._load_in_4bit","quantization_config._load_in_8bit","quantization_config.bnb_4bit_compute_dtype","quantization_config.bnb_4bit_quant_storage","quantization_config.bnb_4bit_quant_type","quantization_config.bnb_4bit_use_double_quant","quantization_config.llm_int8_enable_fp32_cpu_offload","quantization_config.llm_int8_has_fp16_weight","quantization_config.llm_int8_threshold","quantization_config.load_in_4bit","quantization_config.load_in_8bit","quantization_config.quant_method","ray_scope","relative_attention_max_distance","relative_attention_num_buckets","remove_invalid_values","remove_unused_columns","repetition_penalty","report_to","restore_callback_states_from_checkpoint","return_dict","return_dict_in_generate","rms_norm_eps","rope_theta","run_name","save_on_each_node","save_only_model","save_safetensors","save_steps","save_strategy","seed","skip_memory_metrics","task_specific_params.summarization.early_stopping","task_specific_params.summarization.length_penalty","task_specific_params.summarization.max_length","task_specific_params.summarization.min_length","task_specific_params.summarization.no_repeat_ngram_size","task_specific_params.summarization.num_beams","task_specific_params.summarization.prefix","task_specific_params.translation_en_to_de.early_stopping","task_specific_params.translation_en_to_de.max_length","task_specific_params.translation_en_to_de.num_beams","task_specific_params.translation_en_to_de.prefix","task_specific_params.translation_en_to_fr.early_stopping","task_specific_params.translation_en_to_fr.max_length","task_specific_params.translation_en_to_fr.num_beams","task_specific_params.translation_en_to_fr.prefix","task_specific_params.translation_en_to_ro.early_stopping","task_specific_params.translation_en_to_ro.max_length","task_specific_params.translation_en_to_ro.num_beams","task_specific_params.translation_en_to_ro.prefix","temperature","tf_legacy_loss","tie_encoder_decoder","tie_word_embeddings","top_k","top_p","torch_compile","torch_dtype","torchscript","tp_size","tpu_metrics_debug","transformers_version","typical_p","use_bfloat16","use_cache","use_cpu","use_ipex","use_legacy_prediction_loop","use_liger_kernel","use_mps_device","vocab_size","warmup_ratio","warmup_steps","weight_decay","ddp_find_unused_parameters","eval_steps","save_total_limit","Commit","Created","Runtime","GitHub","End Time","Hostname","Notes","GPU Type","State","Updated","custom_step","eval/loss","eval/runtime","eval/samples_per_second","eval/steps_per_second","non_zero_loss_steps","total_flos","train/epoch","train/global_step","train/grad_norm","train/learning_rate","train/loss","train_loss","train_runtime","train_samples_per_second","train_steps_per_second","Tags"
"mistral-7b-lora-training-single-node","n34ahw7a","","","","","","1","true","mistralai/Mistral-7B-Instruct-v0.3","true","false","false","true","false","0.9","0.999","1e-8","false","[""MistralForCausalLM""]","0","false","false","false","true","false","1","0","","","","","false","0","false","true","1800","[]","","","false","0","true","false","false","false","","false","0","2","0","true","false","epoch","false","epoch","","false","auto","false","O1","[]","0","false","false","false","0","false","16","false","false","false","auto","128","silu","4096","false","every_save","<HUB_TOKEN>","LABEL_0","LABEL_1","false","[]","false","false","false","","0.02","14336","false","false","","false","0","1","0","","0.0002","length","1","true","0","passive","warning","true","./logs","false","true","50","steps","linear","1","20","32768","-1","eval_loss","0","7251431424","mistral","","","false","0","32","1","1","","","32","8","","1","3","paged_adamw_8bit","false","./mistral_7b_lora_output","false","","false","false","","-1","mistralai/Mistral-7B-Instruct-v0.3","none","false","false","true","16","false","0.1","megatron.core","LORA","8","false","[""v_proj"",""q_proj""]","CAUSAL_LM","false","false","1","1","false","false","<PUSH_TO_HUB_TOKEN>","false","true","float32","uint8","fp4","false","false","false","6","false","true","BITS_AND_BYTES","last","","","false","true","1","[""wandb""]","false","true","false","0.00001","1000000","mistral-7b-lora-job-extraction-single-node","false","false","true","500","epoch","42","true","","","","","","","","","","","","","","","","","","","","1","false","false","false","50","1","false","bfloat16","false","","false","4.48.3","1","false","true","false","false","false","false","false","32768","0","0","0.01","","","","ba106875f328c2b650843ce6b161694c262bd4f2","2025-04-13T16:32:45.000Z","201780","https://github.com/alexlanxy/JobExtractX/tree/ba106875f328c2b650843ce6b161694c262bd4f2","2025-04-16T00:35:45.000Z","rtx-6000-11","-","Quadro RTX 6000","failed","2025-04-16T00:35:45.000Z","1860","1.07928466796875","2096.0069","0.528","0.528","1","1957272484042506500","2.995983935742972","1866","0.4571378529071808","0.000001714898177920686","0.9061","0.9523297822999288","201777.6623","0.148","0.009","valid models"
"flan-t5-xl-lora-training-rtx6000","9cit0wn2","","","","","","1","true","google/flan-t5-xl","true","false","false","true","false","0.9","0.999","1e-8","false","[""T5ForConditionalGeneration""]","","false","false","false","true","false","","0","0","5120","64","2048","false","0","false","true","1800","[]","0","gelu_new","false","0","true","false","false","false","0.1","false","0","1","0","true","false","epoch","false","epoch","gated-gelu","false","auto","false","O1","[]","0","false","false","false","0","false","4","false","false","false","auto","","","","false","every_save","<HUB_TOKEN>","LABEL_0","LABEL_1","false","[]","false","false","false","1","","","false","true","true","false","0","1","0","0.000001","0.0002","length","1","true","0","passive","warning","true","./logs","false","true","50","steps","linear","1","20","","-1","eval_loss","0","2854475776","t5","","512","false","0","","1","1","24","32","","","24","1","3","paged_adamw_8bit","false","./flan_t5xl_lora_output","false","true","false","false","0","-1","google/flan-t5-xl","none","false","false","true","16","false","0.1","megatron.core","LORA","8","false","[""q"",""v""]","SEQ_2_SEQ_LM","false","false","4","4","false","false","<PUSH_TO_HUB_TOKEN>","false","true","float32","uint8","fp4","false","false","false","6","false","true","BITS_AND_BYTES","last","128","32","false","true","1","[""wandb""]","false","true","false","","","flan-t5-xl-lora-job-extraction","false","false","true","500","epoch","42","true","true","2","200","30","3","4","summarize: ","true","300","4","translate English to German: ","true","300","4","translate English to French: ","true","300","4","translate English to Romanian: ","1","false","false","false","50","1","false","float32","false","","false","4.47.1","1","false","true","false","false","false","false","false","32128","0","0","0.01","","","","df5c610a33149ddcd6028aaa3f55a9c93ace0d1c","2025-04-11T18:22:28.000Z","77056","https://github.com/alexlanxy/JobExtractX/tree/df5c610a33149ddcd6028aaa3f55a9c93ace0d1c","2025-04-12T15:46:44.000Z","rtx-6000-7","-","Quadro RTX 6000","finished","2025-04-12T15:46:44.000Z","1860","0.16089704632759094","778.0649","1.423","0.356","1","766900955995177000","2.995983935742972","1866","0.8427208065986633","0.000001714898177920686","0.7232","0.875237967806997","77018.6534","0.388","0.024","valid models"
"flan-t5-xl-lora-training-rtx6000","tg8gnlcu","","","","","","1","true","google/flan-t5-xl","true","false","false","true","false","0.9","0.999","1e-8","false","[""T5ForConditionalGeneration""]","","false","false","false","true","false","","0","0","5120","64","2048","false","0","false","true","1800","[]","0","gelu_new","false","0","true","false","false","false","0.1","false","0","1","0","true","false","epoch","false","epoch","gated-gelu","false","auto","false","O1","[]","0","false","false","false","0","false","8","false","false","false","auto","","","","false","every_save","<HUB_TOKEN>","LABEL_0","LABEL_1","false","[]","false","false","false","1","","","false","true","true","false","0","1","0","0.000001","0.0002","length","1","true","0","passive","warning","true","./logs","false","true","50","steps","linear","1","20","","-1","eval_loss","0","2854475776","t5","","512","false","0","","1","1","24","32","","","24","1","3","paged_adamw_8bit","false","./flan_t5xl_lora_output","false","true","false","false","0","-1","google/flan-t5-xl","none","false","false","true","16","false","0.1","megatron.core","LORA","8","false","[""v"",""q""]","SEQ_2_SEQ_LM","false","false","2","2","false","false","<PUSH_TO_HUB_TOKEN>","false","true","float32","uint8","fp4","false","false","false","6","false","true","BITS_AND_BYTES","last","128","32","false","true","1","[""wandb""]","false","true","false","","","flan-t5-xl-lora-job-extraction","false","false","true","500","epoch","42","true","true","2","200","30","3","4","summarize: ","true","300","4","translate English to German: ","true","300","4","translate English to French: ","true","300","4","translate English to Romanian: ","1","false","false","false","50","1","false","float32","false","","false","4.47.1","1","false","true","false","false","false","false","false","32128","0","0","0.01","","","","8b5b864885a46440b14404649be974d00e4b0323","2025-04-11T17:25:25.000Z","80137","https://github.com/alexlanxy/JobExtractX/tree/8b5b864885a46440b14404649be974d00e4b0323","2025-04-12T15:41:02.000Z","rtx-6000-9","-","Quadro RTX 6000","finished","2025-04-12T15:41:02.000Z","1860","0.16072234511375427","815.6836","1.357","0.679","1","766900955995177000","2.995983935742972","1866","1.5342320203781128","0.000001714898177920686","1.4499","1.743098221152286","80098.8088","0.373","0.023","valid models"
"flan-t5-job-training-rtx6000-prompt-ordered-fields","m8aiygfn","","","","","","1","true","google/flan-t5-large","true","false","false","true","false","0.9","0.999","1e-8","false","[""T5ForConditionalGeneration""]","","false","false","false","false","false","","0","0","2816","64","1024","false","0","false","true","1800","[]","0","gelu_new","false","0","true","false","false","false","0.1","false","0","1","0","true","false","epoch","false","epoch","gated-gelu","false","auto","false","O1","[]","0","false","false","false","0","false","16","false","false","false","auto","","","","false","every_save","<HUB_TOKEN>","LABEL_0","LABEL_1","false","[]","false","false","false","1","","","false","true","true","false","0","1","0","0.000001","0.00003","length","1","true","0","passive","warning","true","./logs","false","true","50","steps","linear","1","20","","-1","eval_loss","0","783150080","t5","","512","false","0","","1","1","24","16","","","24","1","3","adafactor","false","./flan_t5_model_output_rtx6000_prompt","false","true","false","false","0","-1","","","","","","","","","","","","","","","","","1","1","false","false","<PUSH_TO_HUB_TOKEN>","","","","","","","","","","","","","last","128","32","false","true","1","[""wandb""]","false","true","false","","","flan-t5-job-extraction-rtx6000-prompt","false","false","true","500","epoch","42","true","","","","","","","","","","","","","","","","","","","","1","false","false","false","50","1","false","","false","","false","4.47.1","1","false","true","false","false","false","false","false","32128","0","0","0.01","","","","632ea14f290048f9a32d2c7b250425a9a1432999","2025-04-11T04:31:56.000Z","26428","https://github.com/alexlanxy/JobExtractX/tree/632ea14f290048f9a32d2c7b250425a9a1432999","2025-04-11T11:52:24.000Z","rtx-6000-7","-","Quadro RTX 6000","finished","2025-04-11T11:52:24.000Z","1860","0.16288010776042938","375.0697","2.951","2.951","1","206322826959912960","2.995983935742972","1866","5.00451135635376","2.572347266881029e-7","2.8019","3.39317800556604","26408.0559","1.131","0.071","valid models"